# -*- coding: utf-8 -*-
"""Whatsapp_Chat_Analyser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XIPUXfI9kjFb5kFL9AINiYfNBuxa39oP
"""

import re  #regualar expression
import pandas as pd

f=open('/content/WhatsApp Chat with Yelagiri .txt','r',encoding='utf-8')

data=f.read()

print(data)

# pattern='\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s(?:am|pm)\s-\s'
pattern='\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s(?:am|pm)\s-\s'

messages=re.split(pattern,data)[1:]
print(messages)

# dates=re.findall(pattern,data)
# dates
dates = re.findall(pattern, ''.join(data))

# Concatenate the captured groups to form the desired output format
dates = [match.replace('\u202f', ' ') for match in dates]
print(dates)

df=pd.DataFrame({'user_message':messages,'message_date':dates})
#convert message_date type
df['message_date']=pd.to_datetime(df['message_date'],format='%d/%m/%y, %I:%M %p - ')
df.rename(columns={'message_date':'date'},inplace=True)
df.head()

df.shape

#seperate users and messages
users=[]
messages=[]
for message in df['user_message']:
  entry=re.split('([\w\W]+?):\s',message)
  if entry[1:]: #username
    users.append(entry[1])
    messages.append(entry[2])
  else:
    users.append('group_notification')
    messages.append(entry[0])
df['user']=users
df['message']=messages
df.drop(columns=['user_message'],inplace=True)
df.head()

df['year']=df['date'].dt.year  #sepearting year

df.head()

df['month']=df['date'].dt.month_name() #sepearting month

df['day']=df['date'].dt.day #seperating day

df['hour']=df['date'].dt.hour

df['minute']=df['date'].dt.minute

df.head()

words=[]
for message in df['message']:
  words.extend(message.split())

len(words)

pip install urlextract

from urlextract import URLExtract
extractor=URLExtract()
links=[]
for message in df['message']:
  links.extend(extractor.find_urls(message))

len(links)

x=df['user'].value_counts().head()

import matplotlib.pyplot as plt

name=x.index
count=x.values

plt.bar(name,count)
plt.xticks(rotation='vertical')
plt.show()

round((df['user'].value_counts()/df.shape[0])*100,2).reset_index().rename(columns={'index':'name','user':'percent'})

temp=df[df['user']!='group_notification']
temp=temp[temp['message']!='<Media omitted>\n']

f=open('stop_hinglish.txt','r')
stop_words=f.read()

words=[]
for message in temp['message']:
  for word in message.lower().split():
    if word not in stop_words:
      words.append(word)

from collections import Counter
pd.DataFrame(Counter(words).most_common(20))

pip uninstall emoji

pip install emoji==1.7

import emoji

emojis=[]
for message in df['message']:
  emojis.extend([c for c in message if c in emoji.UNICODE_EMOJI['en']])

pd.DataFrame(Counter(emojis).most_common(len(Counter(emojis))))

df['month_num']=df['date'].dt.month

timeline=df.groupby(['year','month_num','month']).count()['message'].reset_index()

timeline

time=[]
for i in range(timeline.shape[0]):
  time.append(timeline['month'][i]+"-"+str(timeline['year'][i]))

time

timeline['time']=time

timeline

plt.plot(timeline['time'],timeline['message'])
plt.xticks(rotation='vertical')
plt.show()

df['only_date']=df['date'].dt.date

daily_timeline=df.groupby('only_date').count()['message'].reset_index()

plt.figure(figsize=(18,10))
plt.plot(daily_timeline['only_date'],daily_timeline['message'])

df['day_name']=df['date'].dt.day_name()

df['day_name'].value_counts()

df.head()

period=[]
for hour in df[['day_name','hour']]['hour']:
  if hour==23:
    period.append(str(hour)+"-"+str('00'))
  elif hour==0:
    period.append(str('00')+"-"+str(hour+1))
  else:
    period.append(str(hour)+"-"+str(hour-1))

df['period']=period

df.head()

import seaborn as sns
plt.figure(figsize=(20,6))
sns.heatmap(df.pivot_table(index='day_name',columns='period',values='message',aggfunc='count').fillna(0))
plt.yticks(rotation='horizontal')
plt.show()